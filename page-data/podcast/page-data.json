{"componentChunkName":"component---src-pages-podcast-js","path":"/podcast/","result":{"data":{"posts":{"edges":[{"node":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"type\": \"podcast-episode\",\n  \"status\": \"published\",\n  \"slug\": \"/podcast/05-kevin-roose\",\n  \"featuredImage\": \"../../images/podcast-images/05-kevin-roose.png\",\n  \"guid\": \"publicinfrastructure.org/podcast/05-kevin-roose\",\n  \"title\": \"Kevin Roose, The New York Times\",\n  \"subtitle\": \"Presented by the Institute for Digital Public Infrastructure at UMass Amherst\",\n  \"publicationDate\": \"2020-11-17T00:00:00.000Z\",\n  \"author\": \"Institute for Digital Public Infrastructure\",\n  \"season\": 1,\n  \"episodeNumber\": 5,\n  \"episodeType\": \"full\",\n  \"excerpt\": \"We welcome Kevin Roose to the podcast — tech reporter for The New York Times and thorn in the side of Facebook — to talk to us about how platforms' laser focus on growth resulted in building a misinformation ecosystems and algorithms that they don't really understand. Kevin and Ethan talk about what's really the healthiest social media platform of them all, and what Wall Street-style regulation might look like for major platforms. Visit the episode page for show notes and a full transcription of the interview.\",\n  \"url\": \"https://archive.org/download/05.-kevin-roose-the-new-york-times/05.%20Kevin%20Roose%2C%20The%20New%20York%20Times.aif.mp3\",\n  \"embed\": \"https://archive.org/embed/05.-kevin-roose-the-new-york-times\",\n  \"youtubeEmbedURL\": \"https://www.youtube.com/embed/BdZ_6PFmz_A\",\n  \"duration\": 1573,\n  \"size\": 60000000,\n  \"explicit\": false,\n  \"categories\": [\"Technology\", \"Government\", \"Science\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"We welcome \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.kevinroose.com/\"\n  }), \"Kevin Roose\"), \" to the podcast \\u2014 tech reporter extraordinaire for The New York Times and thorn in the side of Facebook \\u2014 to talk to us about how platforms' laser focus on growth resulted in building a misinformation ecosystems and algorithms that they don't really understand. Kevin and Ethan talk about what's really the healthiest social media platform of them all, and what Wall Street-style regulation might look like for major platforms.\"), mdx(\"p\", null, \"Kevin Roose reported and produced the excellent \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.nytimes.com/column/rabbit-hole\"\n  }), \"Rabbit Hole\"), \" podcast earlier this year, covering the rise of the alt right on YouTube. He also maintains the Twitter account \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://twitter.com/FacebooksTop10\"\n  }), \"Facebook's Top 10\"), \", which lists the publishers of the 10 most shared articles on Facebook on a given day, a list that frequently sees legacy news side by side with alt right upstarts.\"), mdx(\"h2\", null, \"Transcript\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Hi, everyone. Welcome to Reimagining the Internet. This is an ongoing podcast series from the Institute for Digital Public Infrastructure at the University of Massachusetts at Amherst. My name is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \", I'm your host. And today we're with tech columnist for the New York Times, author, investigative journalist, a thorn in the side of Facebook and many technology platform companies, I think one of the people doing the best work right now in technology writing, \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \". How are you Kevin?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"I'm doing well. Thank you for having me on.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Thanks so much for being with us. This is an ongoing conversation with smart people who follow the tech industry seeing if we can get beyond just calling out what's wrong with tech and actually trying to get towards solutions for social media that could actually be good for us rather than just not destroy our democracies. And so, we've been starting these conversations with really simple questions. What is wrong with social media at present and what do you think the companies and the rest of us should be doing to fix those problems?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"That's a big question, a big couple of questions. Right now, I think the problems with social media vary widely by platform and by even functions within platforms. So, I think one of the things that unites a lot of these problems is that they were built by companies that were looking to attract growth, that we're looking to attract users and engagement. They were built around the idea that the less friction is involved in sharing something or posting something or clicking on something the better. And so, they have really made design decisions and monetization decisions not thinking through downside risks, not thinking through abuse potential, just purely trying to make the numbers go in the right direction.\"), mdx(\"p\", null, \"They've been hugely successful at that, these companies are very big and very profitable. And I've been writing a lot recently about automation and I have a book coming out next year about AI and automation and the way it is changing what it means to be human. And I think a lot of this, we don't tend to think of the automation, AI conversation in the same breath as the social media conversation, but I think they're related. I think that these companies suffer from an overconfidence in automation.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"So you talk about this a lot with the rabbit hole work, you did a really excellent eight part podcast series that was looking at how YouTube recommends videos and the possibility that YouTube is pushing people towards increasingly radical content. How does that question about automation and overconfidence in automation come into play around something like YouTube?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Well, I think we see on YouTube one of the most advanced forms of automation ever built. I mean, Google has the best AI engineers in the world, they publish the most papers, they win the most awards. And for much of the last decade, the biggest, most profitable AI project at Google has been YouTube recommendations. 70% of watch time on the platform comes from recommendations, and that's a company that is making billions of dollars a year. So I think when we think of the cutting edge of AI, we think of an open AI lab or some Carnegie Mellon research project.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Auto generated text.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Yeah, GPT3 or something like that. But YouTube recommendations are the cutting edge of AI research in this country and probably in the world and I don't think we ever think about that. We just think, \\\"Oh, that's what every other platform does, it recommend stuff.\\\" So I think that the confidence that these firms have in the ability of machine learning to do things like surface relevant and engaging content to people is based on a pretty shallow definition of engaging and relevant. It's based on what they can measure, which is watch time, which is clicks, which is shares. And I think that their inability to look deeper than that, to cook these algorithms to some metric that is more substantive, such as whether something is true or not, for example, is one of their great failures and the source of a lot of their problems.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"And you've been making this point lately on Facebook looking through the CrowdTangle data and let's start by specifying that. Facebook says that CrowdTangle is not necessarily an accurate picture of what's most shared on their site, at the same time they also make clear that they won't give you any information.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Right. I'm wrong according to their secret data that they won't share.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"That's right, yes. In one of my other instances, I'm writing a paper about how we study an audit the platforms and the story of you crossing swords with Facebook over that is actually the opening story of the paper. But this problem with the logic of automation and the logic of algorithms comes out there as well. What's the point that you're trying to make in showing this string of highly emotional, often let's go with factually challenged right-leaning content gaining top engagement marks on Facebook?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Well, I think my point in showing that to people on Twitter was just pretty simple. It was, this is happening and you probably don't know about it because I think people who spend time on Twitter, journalists, researchers, high information news consumers, the conversation there is pretty divorced from what's happening on Facebook, which is 10 times as large. And my goal was not to prove a point about politics or algorithms or anything like that. When I started, I was just seeing this data and saying, \\\"I cannot believe how different this is than what I'm seeing on my Twitter feed, and I bet Twitter might find it interesting to know what's happening on this platform that is 10 times bigger.\\\" So that was all I was trying to do by posting these lists of the most engaged Facebook posts is just simply, check this out. That's interesting, maybe we should talk about that.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I want to push you on this question of what would we do to make things better? That there's at least three things going on with the algorithms that you're talking about.\"), mdx(\"p\", null, \"The first is that they may be hiding from us content that we should know about, even if we don't want to see it, you probably don't know about PewDiePie because you may not need PewDiePie in your life but as a citizen, it's probably a good idea to know who he is and what's going on with him.\"), mdx(\"p\", null, \"Second, there's the danger that the algorithms lead us down a rabbit hole, that we start following someone who's talking about self improvement and very quickly we find ourselves talking about White nationalism or really horrific misogyny.\"), mdx(\"p\", null, \"And then the third is that it just turns out that humans are pretty awful, a good chunk of the time and that when you put forward a Facebook or YouTube, a lot of what people create turns out to be pretty miserable and stuff that's very hard to look at and hard to know how to wrestle with. Is the solution that we build these things without the algorithms or what's the way that we go after that cluster of problems?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"This is strange for me to be casting myself in the role of defender of humans here, but I actually don't think humans at their core are bad. I don't think most people wake up in the morning and say, \\\"How could I enrage myself and others? How could I divide myself from others?\\\" I don't think that's how we're wired, and yet I think that's the behavior that these platforms are built to incentivize. Not because Mark Zuckerberg's evil or Jack Dorsey's evil, or Susan Wojciki's evil and they want to tear society apart. But I just don't think they understand the decisions that they've made around how to measure and maximize certain forms of engagement and what that produces in people. So I actually don't know that I think that we're all just wired this way and that these platforms just reflect human nature. But I do think ...\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I spend too much time in 4chan.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Yeah. I mean, I also spend a lot of time on 4chan, which makes it weird, but I do think that communities have, to use a very unscientific term, vibes. When you go into a space in the physical world, the design of that space teaches you how to act in that space. If you go into a very austere and imposing, government building, the design of that space, the architecture, the columns, the layout, it tells you something about how you are supposed to behave in that space. And I think the same is true of online platforms, that when people go on 4chan or they go into a Facebook group for the Boogaloo movement, or they go onto a YouTube channel for a White nationalist, the design of that community, the architecture of the platform has a lot to do with how they will ultimately behave.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"We talk a lot about norms and affordances when we look at different platforms. So some of the work that I'm doing right now is trying to map what I think of as the Facebook logic. And so, for me, the Facebook logic of course, is as you're identifying high engagement, it's based in part on the economic model, right? We're based on surveillance capitalism, so we need you both to stay and share your eyeballs, but we also need information about you and either you need to put up information or you need to give us behavioral data so that we can follow you and sell the ads. But it has other aspects to it, and part of it is centralization and facelessness, everybody sees more or less the same Facebook, you can't change the affordances. The moderation is invisible, central, behind the scenes is holding on transparent.\"), mdx(\"p\", null, \"So once you get your head around that logic, you can think about different logic's, right? Like, Reddit operates on a very different logic. You move into a space on Reddit and it's still ad supported, it's still tracking you, but the governance there has been handed to a team of moderators and they say, \\\"This is R/aw and if it's not a cute animal, you can't put it there. And by the way, we actually have defined cute very specifically, you can't put up your puppy who's recovering from surgery because that's making people feel bad, that's not actually cute, and if you don't like it, you can become a moderator and become part of it.\\\" So for me, I think that notion of taking the logic seriously makes a ton of sense. Facebook, in some ways, to me fails so much because it is one logic designed for everything two billion people might conceivably do on a social media platform. And it's also one in which they have no control over how its governed, or how the speech ends up working on it.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Yeah, and I think the other piece of this that you've identified is that human led governance is pretty effective, decentralized governance. Wikipedia is our most functional social network. And we don't think of it as a social network, but it is and its product is knowledge and is accuracy and that's what's valued in that community. And if you go into a Wikipedia page and start messing around, you're going to get chastised, you're going to get banned. Moderators have a vested interest in keeping it civil and accurate and not allowing a ton of vandalism and so, there are norms in that community. So I think that part of what Facebook is running up against is just scale.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Yeah.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"But I also don't think any of this as an accident. I think they designed it this way. They are so invested in this idea that algorithms can do as good or better a job at things like assessing hate speech, at things like choosing relevant information for people, at defining authority for various news sources. They just have really under-invested in humans as a source of guidance and wisdom on the job of providing information to two or three or billion people.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I don't want to lose the algorithms piece of it, but I actually do want to dig in on your provocation that Wikipedia is one of our most successful social networks, I think that's absolutely true. I would say you've got two things at work there. One is a norm, which is NPOV, neutral point of view and this idea that we're just going to batter stuff back and forth until we get something that we can all more or less agree with. And it may take the rough edges off of it, it may give us something that's smooth and comfortable and not necessarily as beautifully written, but it's something that we can get our heads around. There's also some incredible technical affordances and probably the easiest one to think about is the ability to roll back. The idea that with a click, you can basically say, \\\"Nope, vandalism, sorry, not worth it.\\\"\"), mdx(\"p\", null, \"And that's an incredibly different logic, either than the chans where you say whatever you want and the stream of time brushes it away or within the Facebook logic, it's your words, you stand behind them and they're sacred and sacrosanct to a certain extent. Wikipedia has none of that sense of sacrosanct, if you're wrong, or if you're right and you can't defend it, it's gone and that's the space that you're agreeing to play within. But let me push you a little further. Can you imagine a vision of social media that isn't just less toxic than the patterns that you've identified, but is good for us? Is something that actually helps us as citizens or is the answer just that we've got to step away from this stuff and step offline or into other forms of storytelling?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Yeah. I mean, I don't think they need to be destroyed to be better. And I think that even within some of these very flawed companies, we see examples of things that are better or worse. So take, for example, Instagram. Instagram, you could rattle off a litany of harms, self image, things like that. But I think most people would agree that on the whole the information on Instagram has a higher integrity than the information on Facebook, why is that? Partly, I think it's because Instagram has chosen not to add features that might degrade the quality of the information on there and make it feel less intimate, less personal, so there's no native reshare on Instagram. You can't click a button and share something. There's also no links on Instagram, which removes a whole category of misbehavior that has plagued Facebook, which is this click bait economy that has grown up both in politics and outside of it and Facebook owns Instagram.\"), mdx(\"p\", null, \"It's not a secret that you can do these things, that you can have a successful platform without those features, but they're so invested in the architecture of the big blue app that it's not clear to me that they're ever going to do that, but they have an example right there in their own company of a social network that is succeeding by not implementing certain features. Sure, it could have maybe added 5% daily active users by putting in a native reshare button, it could have maybe gotten more publishers more invested in the platform by adding links, these decisions have been weighed inside the company and they've chosen not to do them. Goldman Sachs always has this thing about how they're longterm greedy, and I think about that a lot in the context of tech firms, which I think are very short-term focused. I think they're very focused on next quarter's KPI's and next quarter's monthly actives. And I just think they could have been a little bit longterm greedier when it came to things like limiting features that might degrade the quality of their services.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"You can share a sheep a lot of times and you can skin it only once, and maybe the answer is Facebook in becoming this wildly popular network has been skinning its users. Do you see any hope for Facebook or YouTube changing? You've been engaged in some pretty fierce and high profile fights. Do you think the reporting that you're doing is having a difference? Do you see them making any changes?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"I certainly hope so. I mean, I hope that what I've been harping on and yelling about for the last three years has mattered, I think it has. And I've heard from people inside these companies that their internal criticism resonates more loudly when it is in harmony with external criticism. And that they actually appreciate, obviously they don't appreciate all of the criticism, but in certain areas like for QAnon for example, that it actually really helped the people inside Facebook to have people on the outside drawing attention to it and putting pressure on executives because often, it's no secret, these companies act in response to media pressure. So I think they have changed.\"), mdx(\"p\", null, \"I mean, YouTube changed its recommendations algorithm, they said it's been hugely effective in reducing the growth of some channels that were on the extreme end. I believe that because I see these creators who used to get millions of views on everything they posted now complaining that they can't get 100,000 views on their videos. And so, I think that they have done some admirable things there that have probably cut into growth, but may ultimately have saved them a lot of headaches. Yeah, I don't think these are irredeemable platforms, I just think that they have to choose something other than the path of least resistance. They have to choose something other than growth to be their North Star.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Do we see a regulatory role in this at all? Do you think the way to do this is to expose what's going badly on these platforms and let people agitate inside for change, or do you think Congress or the FTC or the FCC is going to end up putting on substantial at some point that's going to force a change in this landscape?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Yeah, I think regulation has a huge role. I mean, I used to cover Wall Street and regulations really have changed Wall Street. There's still some unsavory stuff going on, but it is much harder for big banks to take advantage of consumers in the ways that they did before the financial crisis. And I think that the result of a lot of hard choices and a lot of good regulatory action. And I actually do think there's a good parallel in the world of tech, because I think that in the banking world, one of the things that they did that I thought showed a lot of foresight, was they broke out the biggest banks, they call them, the SIFI's, the systemically important financial institutions, the really big banks, that if they fail, those failures can cascade throughout the system.\"), mdx(\"p\", null, \"And I think that we could do the same thing in tech where once you reach, let's say 100,00,000 users, you become a systematically important technology firm, and your algorithms have to be open source now. We have to be able to see how you are recommending content and what metrics you are maximizing for. We actually have to be able to see your KPI's, like what are you trying to do? And I think that that regulation could make a big difference in reigning in some of the accesses and in just providing more transparency. Right now we have no idea how these platforms work despite years of investigative reporting and attempts by regulators to subpoena documents and interview people. We have no idea how Facebook or YouTube or Twitter chooses what to show us.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"One thing that I've been starting to suggest in my work is that we actually have firms that can do algorithm, it's much in the same way that an accounting firm can come in and look at privileged information. It has a fiduciary responsibility for the company, so it's not going to share it around, but it also has professional responsibility to be bound by certain standards of accounting and to raise their hand when those things are being violated. It's a tough solution because you have to establish the standards and then build this whole space of algorithmic auditors.\"), mdx(\"p\", null, \"But to me, in many ways, it may be more realistic than trying to open source these algorithms, which gets a little hard because it makes them highly gameable. But one way or another, I think that notion of significant technology institutions, city, I think you were using and then audibility would be a helpful place to go. I want to see if we can end on a vaguely happy note. Kevin, what's an aspect of the internet that still gives you joy? What's something that you encounter that makes you feel like you did those days when you were running your own geo cities page?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"It's actually funny, it was a Facebook engineer side project, but there was a Facebook engineer who came out with this \", \"[Winamp skins 00:00:23:51]\", \" library, did you see this going around?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Yeah.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"I just scrolled through that thing for hours. I mean, it was like opening a time capsule of all these skins for the Winamp MP3 player, which I, and everyone else used in the early days. There are some things on the internet that still gives me joy. I've been trying to do more live streaming with some of my colleagues and particularly my colleague, Charlie \", \"[Worsol 00:24:19]\", \" and I have been trying to make a run at becoming Twitch streamers, which is fun. And it's just a new mode for both of us and it's fun and weird in the ways that make me excited. Let's see, I'm really I'm into watching archival YouTube videos, doing a little bit of time warps. I'll watch an NBA game from 1996 and just put that on and ...\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Anything to get away from 2020, right?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Exactly, exactly. So I think escapism is still one of the internet's strong suits and I still use it for that.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"So, Kevin, it was really a pleasure to have you on here. I, and so many other people rely on the reporting that you're doing. And it's really helpful to ask you to take a little bit of that 20,000 or 40,000 foot view on what ails us in this space and what might be done again. Really appreciate your time. Thank you so much for being with us on Reimagining the Internet.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Thanks so much, Ethan. This was great.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Thanks man.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Kevin Roose\"), \":\"), mdx(\"p\", null, \"Thank you.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"We welcome Kevin Roose to the podcast — tech reporter for The New York Times and thorn in the side of Facebook — to talk to us about how platforms' laser focus on growth resulted in building a misinformation ecosystems and algorithms that they don't really understand. Kevin and Ethan talk about what's really the healthiest social media platform of them all, and what Wall Street-style regulation might look like for major platforms. Visit the episode page for show notes and a full transcription of the interview.","frontmatter":{"publicationDate":"2020-11-17T00:00:00.000Z","title":"Kevin Roose, The New York Times","slug":"/podcast/05-kevin-roose","url":"https://archive.org/download/05.-kevin-roose-the-new-york-times/05.%20Kevin%20Roose%2C%20The%20New%20York%20Times.aif.mp3"}}},{"node":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"type\": \"podcast-episode\",\n  \"status\": \"published\",\n  \"slug\": \"/podcast/04-safiya-noble\",\n  \"featuredImage\": \"../../images/podcast-images/04-safiya-noble.png\",\n  \"guid\": \"publicinfrastructure.org/podcast/04-safiya-noble\",\n  \"title\": \"Safiya Noble, UCLA Center for Critial Internet Inquiry\",\n  \"subtitle\": \"Presented by the Institute for Digital Public Infrastructure at UMass Amherst\",\n  \"publicationDate\": \"2020-11-10T00:00:00.000Z\",\n  \"author\": \"Institute for Digital Public Infrastructure\",\n  \"season\": 1,\n  \"episodeNumber\": 4,\n  \"episodeType\": \"full\",\n  \"excerpt\": \"Safiya Noble, author of Algorithms of Oppression and co-founder of the Center for Critical Internet Studies at UCLA, outlines her abolitionist framework for Big Tech. Recorded the day after Jacob Blake was shot by Kenosha, WI police in August, Noble joins us to talk about what it might look like to hold social media platforms accountable for the dangerous speech they help disseminate.\",\n  \"url\": \"https://archive.org/download/04.-safiya-noble-ucla-center-for-critical-internet-inquiry/04.%20Safiya%20Noble%2C%20UCLA%20Center%20for%20Critical%20Internet%20Inquiry.mp3\",\n  \"embed\": \"https://archive.org/embed/04.-safiya-noble-ucla-center-for-critical-internet-inquiry\",\n  \"youtubeEmbedURL\": \"https://www.youtube.com/embed/VqdsYk0iuyk\",\n  \"duration\": 1892,\n  \"size\": 72200000,\n  \"explicit\": false,\n  \"categories\": [\"Technology\", \"Government\", \"Science\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://safiyaunoble.com/\"\n  }), \"Safiya Noble\"), \", author of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://nyupress.org/9781479837243/algorithms-of-oppression/\"\n  }), mdx(\"em\", {\n    parentName: \"a\"\n  }, \"Algorithms of Oppression\")), \" and co-founder of the \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.c2i2.ucla.edu/\"\n  }), \"Center for Critical Internet Studies at UCLA\"), \", outlines her abolitionist framework for Big Tech. Recorded the day after Jacob Blake was shot by Kenosha, WI police in August, Noble joins us to talk about what it might look like to hold social media platforms accountable for the dangerous speech they help disseminate.\"), mdx(\"h2\", null, \"Transcript\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Hey everybody, this is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \" from the Institute for Digital Public Infrastructure. I'm back with this ongoing conversation series on Imagining the Internet. I'm thrilled to have with us today \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \", who is the associate professor of UCLA in the Department of Information Studies. She's also the co-director of the UCLA Center for Critical Internet Inquiry. I know her and you may know her through her really excellent book, Algorithms of Oppression, How Search Engines Reinforce Racism. She's really one of the most thoughtful people out there about how the systems that we use in social media can have indirect or direct harms on us in terms of racism and discrimination.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"She's someone that I'm really looking to for inspiration in terms of sort of imagining different futures. So, Safiya, thanks for being with us, and I'm going to ask you the question I ask everyone, which is, what's wrong with social media right now and what should we be doing to fix it?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"Well, thank you, Ethan, for that lovely introduction and I think that one of the biggest problems with social media is that we have the speed and scale that allows for some of the most harmful kinds of propaganda, disinformation, discriminatory actions, let's say, in advertising, to proliferate. We also have a direct channel to consumers for the distribution of all kinds of, let's say, products and goods that might be harmful, that might be unregulated, that have no oversight, right? There's so many ways in which the speed and scale of the current large social media monopolies work that I think we have to assess the incredible damage and reconsider whether this is a model or a part of the media system that we really want.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I want to talk a little bit about the damage and how we sort of assess and understand that. Early on, in your work that led up to Algorithms of Oppression, you did really memorable research about how totally innocuous searches on Google. Searching for black girls, for instance, had a very high chance of leading towards pornography, where searching for white girls did not. Google has subsequently changed things. You'll get black girls clothed when you search for black girls now, but for quite some time, when you were using Google to search for somebody like black girls, you were getting this highly sexualized content. What's the harm? Explain to us how that constitutes a harm, how that affects us as users of these tools and members of society.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"Well, we know from other forms of media pre-internet, for example, television and film, those industries, that when you circulate exploitive and stereotypical kinds of information or entertainment about communities, especially communities that are oppressed in our societies around the world, that it actually contributes to the dehumanization of those people. So, one of the reasons why I ... in that early study was looking at what happens when you look for girls of color. I looked at Asian girls, Latina girls, a lot of different kinds of girls and women, and found that over and over women and girls were sexually objectified in search.\"), mdx(\"p\", null, \"Now, the challenge here is that the way people relate to search is that it is kind of like a public library. Some people think of it in that way. They think of it as a fact checker. They think of it as kind of the first go to to find out something about anything.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"There's implication of objectivity.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"There is an implication. There's not only an implication of objectivity, but when Google's own kind of moniker is organizing all the world's knowledge, then that actual organizing makes us think that there are some type of credibility or some veracity in the process of sorting through and indexing all of this content on the web. So, I think it's really important, as the public is engaging with these technologies, that they understand that they're actually advertising platforms. Of course, in the case of the highly sexualized content, it's really to do with the fact that the porn industry and other industries like it have more money than children and girls and even women.\"), mdx(\"p\", null, \"So, I think we have to ask ourselves this idea that those who can buy their way to the top can control certain narratives in our society. That really is what I was trying to point to more than anything in the book, is that we have a lot at stake when we leave our information knowledge landscape to these kinds of advertising companies that really are not invested in truth.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Right? So, in the case of search engines, the concern in many ways is we have something which is a proxy for truth, maybe a stand in for truth. It's an extremely imperfect stand in, but when you really unpack it, what it is is a marketplace. It is more advantageous for porn companies to be advertising on black girls or Asian girls than it is for an NGO, or for women's rights organization. Then, there's the strong possibility that we're going to have to be encountering that ad content. How does this play out in the social media spaces? Why does that relationship between advertising that the market associated with it, and the content that spreads on social media, why is that of such primary concern for you?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"Well, one of the things, Ethan, you and I both have been on the internet for a very long time. I'll tell you, we remember the pre-advertising days, and of course, the many models that came about to try to monetize people's activity and access to entertainment, and ideas, and all kinds of things on the web. So, first of all, we have this kind of publicly built infrastructure that was funded by taxpayers, in the kind of early internet days, then the move to commercialize the space. What it means is that the largest most moneyed actors in the world, and by that, I mean, organizations, businesses, governments, really are able to control the kinds of information that we come into contact with.\"), mdx(\"p\", null, \"Now, that might be great on some levels. I think it's really helpful. I'd love to see, for example, the universities and the public libraries of the United States have a really big visible space for librarians and other kinds of information professionals, for example, to help curate and help us navigate through. In fact, you remember the early web, people thought of it as a virtual library. So, what we have though, instead, is this profit imperative, where return on shareholder investment is really the most important imperative in the social media and kind of big tech landscape.\"), mdx(\"p\", null, \"What that means is, if people are harmed, and when you are talking about, let's say a little bit of propaganda, racist disinformation, hate speech, all kinds of things like that, only a little bit can grow to impact millions of people very quickly. That seems to be the collateral damage that big tech is willing to pay. They're willing to pay very minor fines when they're, for example, breaking the law or they're found in violation of civil rights law. The penalties are pretty low, they're kind of pocket change in relationship to the kind of return. Well, what that means then is the most vulnerable people in our society are the people who pay the highest cost and have the least amount of protection.\"), mdx(\"p\", null, \"I think that's something that it's just it's unsustainable. Of course, every day we just saw, in the last few hours, Jacob Blake being shot in the back, Ahmaud Arbery, George Floyd, Breonna Taylor, there's so many people we could name. Part of the, I think, way in which African-Americans in the United States, for example, are dehumanized through so much kind of vicious incorrect and stereotypical kinds of information that moves through these social media platforms really has a cost. It's not just the people that are harmed, but it's all of us who are witnesses to the harm and have the secondary trauma associated with the harm.\"), mdx(\"p\", null, \"I think we have to think about how we are going to re-imagine the kind of societies we want and what role these technologies play in bringing that forward.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I think we should dig in a little bit to the situation with Jacob Blake, because it has some very direct situations where we might be able to trace harm back to social media. So, three days ago, Jacob Blake was shot in the back Kenosha, Wisconsin by Kenosha Police. He had been trying to break up a fight. He'd been entering his own vehicle and he was shot seven times in the back. As we're recording this, his family's reporting that he's alive, but paralyzed below the waist. There have now been nights of protests in Kenosha. Last night, things got very strange where not only did you have the police attacking protesters with tear gas, but there was a group of what appear to be Boogaloo boys who were armed people claiming to protect businesses in Kenosha area.\"), mdx(\"p\", null, \"What appears to have happened is that one of those people, who may be a minor shot, a number of protestors and killed at least one of them. So, we're now at this situation where we're having peaceful protest as the result of incidents that are being documented, and the documentation is being spread on social media. We now have people coming to these protests to protect or to counter protest armed, and this is a movement that seems to come entirely out of social media. Boogaloo is a reference to this idea that we'll have Civil War, two electric boogaloo, and you have white ethnic nationalists as well as a lot of just anti-government forces who seem to be egging this on.\"), mdx(\"p\", null, \"Is this the time that we just shutdown Facebook, and Reddit, and Twitter? What do we do at this point, Safiya? These tools that you correctly identify seem to be causing a great deal of harm. This really now seems to be turning into matters of life and death.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"It is, and I'll tell you that if there were any other media sector that was allowing for the organization of armed militias to come out and kill Americans, let's just keep it in the US context for a moment, those radio stations would be raided by the FBI. There would be potentially a crackdown. Certainly, we know that for civil rights organizations in the history of the United States, especially the more recent history of the last 50 years, whether it's the American-Indian movement, the civil rights movement, Puerto Rico independence movement, the antiwar left in Vietnam protesting the Vietnam war. We know that if there were attempts and when there were attempts to organize people, for example, to stand up for civil and human rights, that the US Government, in fact, raided those organizations and facilitated the shutdown of movements.\"), mdx(\"p\", null, \"So, it's interesting to me to see right wing, far right extremist, fascist, white nationalist, neo-Nazis these are not all interchangeable terms, but these types of organizations are allowed to not only march up and down our streets with semi-automatic weapons and threaten and also kill peaceful protestors exercising their constitutional rights. But we also have companies that facilitate their ability to communicate, gather, and organize. Of course, I'm talking about Facebook, but also there are others. So, I find this incredibly disingenuous. I think that one of the reasons why these large social media companies have escaped accountability is because they have diluted the public officials into thinking that they are simply neutral tools.\"), mdx(\"p\", null, \"That they are not responsible in any way for the content that moves through their systems. Of course, that's like saying that the cable television industry isn't responsible for the content that they broadcast because they're just the cables underground. That's just a ludicrous proposition. I think we're going to have to really revisit the way in which these companies are framed. It's not a fait accompli that they are here to stay either. Let's remember other technologies. If we pull back and take a longer view, we might remember that there are different kinds of industries and products and services that have come to market. That have been based on different kinds of economic arrangements, that are no longer with us.\"), mdx(\"p\", null, \"Because we decided that they must be abolished, or that they were too harmful, or that the cost was too high, or they were regulated in a way that really discouraged their kind of profiteering through exploitation. I think that we might need to take some of those lenses to some of the existent technology, too.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Before we get into abolition, because I do want to think about that with you, because I think it's one of the most provocative ideas that you're putting forward and one of the most important. I do want to push back slightly and say that there's different models of infrastructure, cable TV carries Fox news even when it's crazy. If it ends up carrying OANN rather than carrying Al-Jazeera America, those are very conscious content choices. I think a lot of these tools would like to argue that they're closer to a common carrier. It's closer to a telephone call or a private letter, where they're not going to intervene and deal with the content. You obviously think that they lean closer to the cable system, making the programming choices than to the common carrier.\"), mdx(\"p\", null, \"How do we sort of understand that in the case of something like Twitter? To what extent is it making those choices that are closer to cable TV and less like telephone or private letters?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"Well, it's difficult to make a telephone call to 10 million people in 48 hours. So, I find that to be a limited way of thinking about it. I understand it kind of from the early ISP dial up model of connectivity. But I think that our infrastructures have also evolved significantly. Now, we're talking about broadcast capabilities that are happening in something like Twitter, or in Facebook, or other types of platforms, YouTube. So, that seems to be, I think, the common carrier model. We've far eclipsed that let's say maybe by 25 years, at least. Now, we're into a situation where you can, one to many, one to millions of people, broadcast content.\"), mdx(\"p\", null, \"Networks and other kinds of broadcasting industries have to think about their responsibility. Now, they have different kinds of oversight, let's say, by the Federal Communications Commission. I think in the case of social media and big tech broadly that we might be thinking at looking at the Federal Trade Commission. This is one of the things that I argue in the book, is that there's been so much focus, I think, on net neutrality in the FCC, again, in that kind of early model and early paradigm. But now we're talking about direct consumer harm, and I think that we need to move. We could even go further then in the FTC and we should say, \\\"Should the Department of Justice be looking at the kinds of activities that happen in these spaces and places?\\\"\"), mdx(\"p\", null, \"I think that the tech industries had such a powerful lobby and a powerful hold on our imaginary about what they are, and that's dangerous. It doesn't mean that necessarily we want to do a way with every dimension, but I think that we are not properly naming what these technologies are lends to the confusion. If we could frame them better, we might be able to better figure out what they are and what they should be responsible for.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"A debate like Section 230 immunity feels very, very different when we're talking about someone posting a webpage for three or four people versus someone with YouTube channels that are reaching millions of people. Somewhere in there, there has to be a distinction between what feels like that one-on-one private communication and what feels more like broadcast. You've talked a little bit about the notion of something parallel to a consumer finance protection bureau, some of the work that Elizabeth Warren and others have done. Can I get you to flush that out a little bit?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"Sure. I think this is a moment where kind of with the opening of the policy community thinking differently and more rigorously, I think of this as a time for scholars who really understand these systems to come forward with ideas. So, of course, I have many different ideas. I'm not sure that any of them will be taken up, but I certainly have talked with you about things like a consumer technology protection board, right? Modeling off of what the banking and finance industry did to really harm millions of Americans through their mortgage schemes and frauds. They're kind of betting against Americans and betting on their failures.\"), mdx(\"p\", null, \"One of the greatest, I think, things we want to remember about the mortgage crisis, which triggered Elizabeth Warren starting the Consumer Finance Protection Board and Rohit Chopra, who is our commissioner on the Federal Trade Commission also worked closely on that, is that we have the largest, for example, wipe out a black wealth in the history of the United States. Imagine all the gains, since emancipation, all of the gains in terms of wealth building effectively wiped out by Wall Street with the gamification, which quite frankly was facilitated by new predictive algorithmic modeling that was not previously possible. So, when we think about the implications of that, I think we have to get very serious about what kinds of harms and what kinds of remedies.\"), mdx(\"p\", null, \"One of the, I think, failures of the consumer finance protection board is it really didn't provide enough remedies to individuals. So, I knew many people, for example, who have lost their homes, this is anecdotal, but I'll just say, okay, they reported Bank of America or they reported Wells Fargo. But in the end, it was the industry that got the bailout, not the homeowners themselves, they were never in a position to repurchase. Those same speculators went in and then snapped up all those properties for pennies on the dollar. If we think that's not connected to things like the affordable housing crisis right now, then we need to dial into cities like Los Angeles, where I live, in New York, and other, Chicago, or other major cities, where people just will never be able to own homes again.\"), mdx(\"p\", null, \"So, I think we've got to think about models that provide remedies to the public for the harms that they experience. Also, that maybe where damages might actually have to be part of the model, too. So that if you harm, you are responsible in terms of damages. The way that the American models of thinking through harm and protections through the legal system have really not often fallen on the side of victims, but rather on the side of perpetrators and large organizations and powerful people.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"You and I are both very much engaged in this question of imagining different possible futures. One of the things that you've said that that has really stuck with me is this idea that we can change economic models. You've made the argument that the US changed one of civilization's greatest injustices and economic model based on the enslavement of people, based on their ethnicity. The United States that was, in many ways, literally inconceivable without the institution of slavery became a United States that is trying to figure itself out post that institution. Changes on that scale have happened, need to happen, makes it possible to sort of imagine what a social media or an internet past surveil and advertising looks like.\"), mdx(\"p\", null, \"Talk to us about what that idea of abolition means in the social media space and what sort of space you might imagine if we abolish some of these models that we're currently thinking about.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"Yeah. Ethan, I appreciate you bringing in that because I have been talking for some time now about the, I guess, in situating my own stay in the matter if I have a say. I really do imagine myself as more of a tech abolitionist probably than anything. When I say that, what I'm invoking for example is the institution of slavery and enslavement. Of course, one of the reasons why we pull back when we look at history is because we understand that there were arguments to be made, that the US economy could not function without a slave economy. It was only a handful of people who were abolitionists.\"), mdx(\"p\", null, \"Who argued about the ethical and moral imperative that was at stake for the country, when it built its society on the notion that there had to be a permanent disposable underclass of people who had no rights and had no say over their lives. The effects of that are still with us. So, it's not like that was hundreds of years ago. We are still living. People, my generation, I'm Generation X, our grandparents, many of our grandparents were sharecroppers. They were just one generation out of enslavement in terms of it's real practice and entrenchment. So, I think that when we think about taking on something like big cotton, or I'll fast forward to another industry we thought was infallible, which is the big tobacco.\"), mdx(\"p\", null, \"There was a time when people could not imagine not having big tobacco as a prominent marker in our society as smoking was. When I tell my students, for example, that probably the doctor who delivered me had a cigarette hanging out of his mouth while he was ... Well, my mom probably chain-smoked right after she gave birth. People can't imagine that now, young people, but that tells you so much, and big tobacco is also really interesting because in many ways it's parallel to pouring millions and millions of dollars into research that was favorable to its own interests. It had powerful marketing and advertising that convinced people that they needed it, and they wanted it.\"), mdx(\"p\", null, \"It had huge secondary effects on people who didn't even choose and want to participate. It created a public health crisis that disproportionately impacted poor people and poor people of color. It was predatory. So, I think that's also a model that we can look at and other industry and say, Well, what happened there?\\\" Well, what we know happened was class action lawsuits. We know that the tobacco industry had to pay basically restoration back to the public. It had to put billions of dollars that were firewalled off from their ability to influence, that went into research, that helped the public understand the harms. Now, it doesn't mean that people can't smoke, but it does mean that people understand what they're doing now when they're smoking.\"), mdx(\"p\", null, \"I think we need a similar kind of movement around big tech, where people at least have the opportunity to understand what they're doing. It's not just a fait accompli that it's ubiquitous and it's everywhere, even if it causes all of these various kinds of attendant harms.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"So, if I'm hearing right, the model is, in some ways, sort of a post-tobacco model, tobacco settlement model, there is a documentation of the harms. There is a holding big tech \", \"[inaudible 00:27:18]\", \", the funds that are used for education. What do we build in its place? If we know that what we built now is dangerous and exploitative, but we also know that social media is unlikely to dissolve, what does the post-big tobacco, the post-big data social media look like?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Safiya Noble\"), \":\"), mdx(\"p\", null, \"Well, I don't think it's a forgone conclusion that social media is here to stay. All right. The reason why I say that is because I think we've thought of other kinds of media that we thought were here to stay, that really changed a lot with other opportunities or other possibilities that came along. So, one of the challenges here is that if social media continues on its same track, it's really going to devolve into such a cesspool. People are not going to want to be there. They're not going to want to participate. We already see the makers. What if the cautionary tales, this is why I love being a researcher, because I feel like we spend our lives trying to see and understand, and then communicate out to the public what's happening.\"), mdx(\"p\", null, \"One of the things that I find interesting is that the makers, for example, of these technologies have their own nannies sign agreements that they cannot allow their own children to participate with these technologies, that they can't post their photos to Instagram. That they can't be on devices when they're with their children. So, they already know themselves about the addictive qualities of these technologies and about what it means to be classified, and documented, and cataloged into these systems from birth, and how harmful, and what the consequences long-term might be.\"), mdx(\"p\", null, \"So, I think we're going to see, for example, the first-generation soon of children who are adults who try to run for office, who try to become teachers, who try to become social workers, who try to do all kinds of things, and who will be damaged, in fact, or barred or precluded from doing some of those things because of this long history of their lives lived on social media. So, I want to offer that we might, through time, see that this did not serve us. That it actually undermined participation in public life, participation in education and employment opportunities. We're already seeing these kinds of things emerge and we're documenting these things.\"), mdx(\"p\", null, \"So, I say, it isn't a fait accompli that these things will be here forever, and maybe, maybe we don't need industrial skill technology. Maybe we will go like the ... I'd look metaphorically always to other kinds of movements, maybe like the response to the industrial level food industry and farming industry, we will have a slow food or a slow tech movement. Maybe we will find that an organic, slow, localized kind of connectivity that doesn't demand a 24 by seven type of connectivity and drive an addictive quality of life, might be more enjoyable. We have no idea what's possible and plausible, but I think it's incumbent upon us to try to imagine and try to dream about the kinds of lives and societies and communities we want to live in. That's what I enjoy thinking about and trying to offer into the conversation.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Safiya Noble, author of Algorithms of Oppression and co-founder of the Center for Critical Internet Studies at UCLA, outlines her abolitionist framework for Big Tech. Recorded the day after Jacob Blake was shot by Kenosha, WI police in August, Noble joins us to talk about what it might look like to hold social media platforms accountable for the dangerous speech they help disseminate.","frontmatter":{"publicationDate":"2020-11-10T00:00:00.000Z","title":"Safiya Noble, UCLA Center for Critial Internet Inquiry","slug":"/podcast/04-safiya-noble","url":"https://archive.org/download/04.-safiya-noble-ucla-center-for-critical-internet-inquiry/04.%20Safiya%20Noble%2C%20UCLA%20Center%20for%20Critical%20Internet%20Inquiry.mp3"}}},{"node":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"type\": \"podcast-episode\",\n  \"status\": \"published\",\n  \"slug\": \"/podcast/03-evan-henshaw-plath\",\n  \"featuredImage\": \"../../images/podcast-images/03-evan-henshaw-plath.png\",\n  \"guid\": \"publicinfrastructure.org/podcast/03-evan-henshaw-plath\",\n  \"title\": \"Evan Henshaw-Plath, Planetary.Social\",\n  \"subtitle\": \"Presented by the Institute for Digital Public Infrastructure at UMass Amherst\",\n  \"publicationDate\": \"2020-11-03T00:00:00.000Z\",\n  \"author\": \"Institute for Digital Public Infrastructure\",\n  \"season\": 1,\n  \"episodeNumber\": 3,\n  \"episodeType\": \"full\",\n  \"excerpt\": \"Evan Henshaw-Plath (aka Rabble), founder of Planetary.Social and member of Twitter's founding team, joins the podcast to talk about decentralized social media, how context collapse makes content moderation on platforms like Facebook and Twitter impossible, and building a platform that's safe for people like furries while keeping away people like neo-Nazis. Vist our episode web page for links to Planetary.Social and a transcript of this interview.\",\n  \"url\": \"https://archive.org/download/03.-evan-henshaw-plath-planetary.-social/03.%20Evan%20Henshaw%20Plath%2C%20Planetary.Social.mp3\",\n  \"embed\": \"https://archive.org/embed/03.-evan-henshaw-plath-planetary.-social\",\n  \"youtubeEmbedURL\": \"https://www.youtube.com/embed/4ORPxrqavdY\",\n  \"duration\": 1655,\n  \"size\": 63300000,\n  \"explicit\": false,\n  \"categories\": [\"Technology\", \"Government\", \"Science\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Evan Henshaw-Plath (aka \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://twitter.com/rabble\"\n  }), \"Rabble\"), \"), founder of Planetary.Social and member of Twitter's founding team, joins the podcast to talk about decentralized social media, how context collapse makes content moderation on platforms like Facebook and Twitter impossible, and building a platform that's safe for people like furries while keeping away people like neo-Nazis.\"), mdx(\"p\", null, \"Learn more about \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://planetary.social/\"\n  }), \"Planetary.Social\"), \".\"), mdx(\"h2\", null, \"Transcript\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"I am thrilled today to have my friend Evan Henshaw Plath, also known as Rabble. He is an activist, a technology-driven organizer, a software developer, a member of the founding Twitter team, and now the Executive Director and high Poobah of Planetary.social. Did I miss anything in their Evan?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"No, that's about right. Yeah.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay. So we're asking everybody the same question in the series and it's really pretty simple. It's a twofer. What is wrong with social media, as we look at it now in August, 2020 and what should we do to fix it? And in your case, of course, you're very actively involved in fixing it with Planetary.social. But let's start with this question of what's wrong with social media right now? And maybe take us back a little bit to your role with Twitter and how we got here.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Social media, first of all, we use it all the time. It's transformed the world, it's transformed how we connected, it's transformed culture and politics. And so it's easy to say everything is wrong with it, but actually there's a lot that's super powerful and good about it.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Right.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And so I think that we are much better off in the world having it than when we didn't have it, even though what we built is pretty flawed. So it's important to understand a bit of the history of where Twitter came from and how it constructed. So the originally the company was funded by Evan Williams, who had been very involved with early blogs and Blogspot and Blogger. And we were trying to build a democratized radio by creating podcasting. And so we built podcasting application and we weren't very good at competing with Apple. Even Apple 15 years ago was a massive company with a lot of resources. And so Apple crushed us and we said, \\\"Oh, well we should build something different,\\\" because we didn't win in building this podcasting thing. And a couple of us in the company had been working with Tad Hirsch, who was at the time, a doctoral student at the Media Lab.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"And is now teaching over at Northeastern.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Yeah. And so he had created this text message-based social network for protests, where you could keep small groups of people or large groups of people really easily up to date. And so what my friend Blaine and I did was we basically went in and sort of rearchitected the technology so that those text messages could be delivered and we use that during the election cycle in 2004, both for protests and get out to vote.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"How do we get from this sort of tool about, \\\"Hey, come to the protest,\\\" to Twitter's paradigm of sharing media, sharing snark, all the many layers of things that Twitter is and isn't today, and in some ways is a social network that punches disproportionately above its weight, given the presence of the US president and all these journalists on it?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"So what happened was we said that the text mob thing that Tad had built lacked a bit of that, the way in which blogs worked. And so we called Twitter microblogging at the time, and the idea was to make it so that you didn't have to have two way relationships so that I could talk out to the world and then I didn't have to listen to everybody who was hearing me. It's not a two-way friendship, so you could do broadcasts and then you could build an audience around who you wanted to listen to and who they wanted to listen to.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"And this is 180 from Facebook, which required reciprocal friendships from day one.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And initially at this point, Facebook had no newsfeed at all. Facebook was closed within each individual university campus. You had to have email addresses and it was not a published to the world.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"When some of the Twitter executives now tell the story, they talk about it a little bit, almost like a workflow tool, almost something like what we would think of Slack as. Is that part of the heritage as well?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"No, not really. It was very much text messaging, activism and blogging, like very much has its roots in early blogging culture.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Got it.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And because of that, there was an open API and then there was RSS feeds and all sorts of people built all sorts of clients. And the way Twitter's innovation worked is it happened all at the edges. So the users created everything. They created inline images and short links and retweets and the app, actual at and hashtags. And so Twitter's innovation and social, it's not like someone designed Twitter as it exists today. The users of Twitter created what it became and Twitter, the company, just supported, adopted, cultivated this garden where innovation can happen.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"How long did you stay with Twitter, the company, and what led you to break away?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"So I stayed there for the first two years of the company. But it was, at the time, a very open company. So I still had root access on all the servers for several years after I left. And people who weren't employees would contribute code and people who were former employees would write code. And it was never very defined, like there were people getting paid, but there were people working on it not getting paid as well.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"So it was just a very fluid boundary at that point?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Exactly. And what happened over time was Twitter got big enough that some point people are like, \\\"Hey, we should have a business model.\\\" And the business model that was adopted was an advertising model, which has never been particularly successful for Twitter, and it still isn't particularly successful. But in order to make that advertising model work, Twitter had to get rid of some of its openness.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And basically, sort of enclose what was the commons run by a company, but functionally a commons because it was collectively governed and it was a collective resource and collectively created. And by enclosing it, they were able to make a business that was sustainable, and has a huge impact on the world for being a relatively small business.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"What is it that's wrong with Twitter now, with social media more broadly, that sort of brought you back to this initial question of how do you build an open social media ecosystem?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"So a few things. One, Twitter over its evolution, made a bunch of decisions about this closing things down. They closed down third party applications. They've closed down the project to do structured data that aren't texts in your tweets. They closed down the federated thing, so Twitter originally worked like Mastodon in terms of being federated. And a bunch of us who had been working on it, kept thinking what if that other path had been taken? And so I kept looking at that model and saying, \\\"Well, maybe we should reopen that box and do something there. Can we make the technology work?\\\" And then I came across Elinor Ostrom's work on the economy of the commons, and I realized that what we'd created in social media ecosystems is a kind of public. It's a public that's governed in different ways. So in some parts of the world, it's very heavily governed by the state. And in China, the state is very interventionist about who can say what and what can be said. And the state defines the regulation that the social media companies then implement.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Right.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"In the United States, those very laws they fare in which the corporations decide all of the rules of this space and the state does very little. And so the American system is a lot like a shopping mall. A shopping mall feels like a public space. It feels like you have everybody together. But if you try and hold a protest in a shopping mall, they will very quickly say that this is private property and the first amendment doesn't apply in the way you think it applies.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Right. It's a privately owned public space. And as such, it has some of the affordances that a public space has, but fewer protections than one might hope it would have. How do you do something different in constructing a de novo social network? What is Planetary and what is Planetary trying to do that's so different from what else is out there right now?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"So part of it is Planetary to saying that the space we should have should function like a commons, function like a space which is collectively governed on a certain rules with enforcement that provides economic and social value to the participants of it, but which is not owned or controlled by a single entity. And so in order to do that, you need to have a vision of it which says this isn't a flat public sphere where you're trying to put everybody together in the same conversation. And this is part of the value of Twitter is it's a single public space where I can reply to anyone else, I can have hashtags and everything else. So you create this collective conversation, but you also create this sort of collapsing of context. We need to design something that is both governed as a commons and creates the structures by which communities can run themselves, define their norms and enact sanctions as a collective entity, without going back to a corporation that needs to kind of define the rules.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"On a system like Twitter, there's really no transparency about what content is being blocked. There's not a ton of transparency about how the terms of service that you probably haven't read, but have agreed to are being enforced. Everything about the governance is opaque and what you might actually want are spaces that frankly help us understand how to be better democratic citizens, actually help us figure out how we govern the spaces that we are choosing to take part of. So how does Planetary support this notion of multiple spaces and this notion of governance of those spaces?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"We exist within a network of people we know, within social circles, and we normally have heard the conversations within those social circles. And so when you open up Planetary or any of the other compatible Scuttlebutt apps, Scuttlebutt's the underlying protocol, and then what you see is just the subset of the world around you. It's as if you went into a forest at night and you had a really bright light, and you know that the forest might extend for miles, but the part of the forest you see is the few hundred feet around you. And if you move and set up a light somewhere else, then you'll see another part of the forest and \", \"[crosstalk 00:12:24]\", \".\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Conversation. And so by doing that, we scope our social interactions around communities, and you're much less likely to have that sort of random person or the conflating of different communities.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"So basically, we're sort of focused in on a subset of the graph. And so we might hear the conversations that approximate to us, we're not necessarily hearing conversations that are all the way on the other side of the social graph. What happens when people in that neighborhood argue or disagree about what the rules should be for what's acceptable in a conversation?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"So there's a couple of things that happened. One thing we had on the network is not in our application, but with compatible applications, a bunch of Norwegian neo-Nazis created some pubs, these are servers that relay messages, and they translated some of the open-source applications into Norwegian. And they set up their sort of corner. And the rest of us are like, \\\"Well, we don't really like Norwegian neo-Nazis.\\\" And so we found the points at which their network bridged and we set up blocks. So the messages don't relay back and forth.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And so what happened is we created this segmented network and you could either be part of that one or a part of the larger network, and there's social punishment for someone who tries to set up that relay. So if you're like, \\\"Oh no, I really want to get the neo-Nazis into the larger conversation,\\\" you can do that. But then there's an awareness of who's doing the blocks and we have this thing called a trust net protocol, which is an actual way of calculating how much you respect and how much you sort of delegate authority to the people around you and who you delegate it to, to make those decisions about how far you want to extend your network in different directions.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"We should stop here and just talk a little bit about some of the problems that happen when you create either a distributed network as Planetary is, or a federated network as Mastodon is.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Yep.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"These are both ways of trying to take control away from a central figure. And in many ways, this is much closer to the internet, perhaps pre-2000, where it just wasn't all that hard for anyone to connect a server to the net and there was a general sense of you're really only responsible to whoever is providing you the connection. When I teach this, I often talk about the Kremvax hoax. And this was this idea in the late eighties, early nineties, that the Kremlin had attached a VAX mini-computer to the net through Finland. And the reason it worked as an April Fools' joke was that it was totally plausible.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"It was perfectly reasonable for Finland to give a connection to the Kremlin and to put Kremvax on there, and people responded to it with, \\\"Okay, sounds good. Let's see how it goes.\\\" We see the same thing happen often now within distributed and federated networks. And it's simply a product of releasing open source software and protocols that can be connected to. Within Mastodon, there's been a split over Lolicon. So basically, hand drawn erotic imagery of children, which has a different role in Japanese society than it does in US society, it may be more acceptable, and what's happened is much what you're saying. There are a lot of Mastodon operators who basically said, \\\"Sorry, we are simply not going to federate. We'll be part of the same network. We're using some of the same protocol, but we're not going to route messages to or from you because we don't want that content there.\\\" So Planetary has the same ability to do this, even though it's a little different from a federated network. How does Planetary differ from Mastodon and other federated networks?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"So federated networks, your account and your identity and the structure of who you're connected to exists on a server that someone is running. And sometimes that's an individual person, sometimes that's a company, sometimes it's a collective of people. Those are the people who have the moderation tasks. And so you don't have direct connections coming into your laptop or your phone. They come into the server and then the server manages your relationships.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"With Planetary and our Scuttlebutt protocol, the way it works is there's no federated servers. There's these relay servers, but they don't have the control the way they do in Mastodon. And so you have a set of relationships of people that you have contacts with. And those contacts have a numeric value between one and negative one.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Zero contact means I am neither blocking them nor following them nor relaying their content on to my friends. And a one means, please relay this on to everybody I have.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Right.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And so that fractional number is not just do I want to see this person's contacts, but my judgment about their relations, what I think they should be reflected out to the broader world.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay. So it's a reputation system, but it's also a control over how information passes within the system. Is that all transparent to the user? Can I look at this and say, \\\"Evan, I'm pretty persuaded by this. I'm going to bump you up from a 0.6 to a 0.8\\\"?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"No, no, we hide it. Maybe we need to expose it. And if you are a developer, you can go and connect to people and see what numbers they are and create visualizations of it. And the cross net software we do goes and uses those numbers to handle auto blocking and a bunch of other things about who we should expose you to, who we suggest you follow, that kind of stuff.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"And it might extrapolate from my behavior. If I amplify you a number of times, it probably increments your score up or something along those lines.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Yeah. And this is an idea that's not unique to Planetary or Scuttlebutt. One of the things I've been doing is involved in Twitter's new decentralized project called Bluesky, which is basically an attempt to create, and a decentralized version, not of the scoped commons based model that Planetary is building, but of that public sphere. And a critical aspect of that is saying the algorithm about what content you see shouldn't be singly held by a corporation. But rather, that feed algorithm needs to be something that you could plug in different versions of.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"I do want to ask you maybe two questions that come up for me out of that. One is just about a peculiarity of secure Scuttlebutt and therefore about Planetary, which is that this network is permanent. Nothing is deleted. Why is that and how is that going to change social interactions?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"So I think it's a mistake. And what we did with building it is we set it so that you can run it either a permanent or in a mode where you can opportunistically delete stuff, but you don't have to. If I send you an email, you don't have to keep it forever.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Right.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"But I don't know whether or not you keep it.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"And you don't have any control over whether I keep it forever. This is simply a property of distributed systems. You've put something out in the world, it has your cryptographic signature on it. As long as I retain a copy of it with your legitimate cryptographic signature on it, that content cannot be deleted.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Yeah. And so what we did was we took the cannot be deleted and continued to sign it and made it so it can be deleted, but you never know whether or not the people you're requesting deleted do delete it.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Got it.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"We call it a soft delete. It's asking politely for people to delete stuff.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"When you sign up for Planetary now, you're running an iOS app. The signup is really weird. It asks you just what you want to be called and a question about what year you were born in, presumably to have some bar for minors. And then I assume that what's happened behind the scenes is that I now have a private key stored on my phone that I'm going to be using to sign messages, right now on Planetary. But at some point in the future, I could open up cosmic.social, and if it speaks to Planetary protocol, I could build different spaces with different affordances or norms, but it would still be open to people who have the Planetary key pair on their phone.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Yeah. And in fact that already exists. So you could go to the Feedless.social, and create an account, and it will store your key pair in your browser like local storage.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And you can then redeem an invite or follow someone who's on Planetary.social on their phone and see each other's posts back and forth.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"If you're using Feedless and you decide that you would rather use Planetary, you can take your keys and you can move them over to Planetary and all of your followers and all of your content move with you.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Talk to me about how Planetary grows and gains users. Obviously it's in an early beta right now. It's clearly changing a lot, but you're going to be moving into a world where Twitter is also trying to build something highly decentralized. How do you see Planetary attracting users? Are you going after individuals? Are you going after communities? What are the use cases for the people you're trying to bring into the project?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Really we're going after communities of people, because people are social animals and building social software for individuals doesn't make a ton of sense. We're looking at communities of people who have particular needs in terms of not being satisfied with the existing system. So there's communities of people who are violating the rules on existing social media platforms, who we don't want, just like \", \"[inaudible]\", \" folks went over running on the ActivityPub Mastadon protocols. We're not seeking out those people and we don't want them using our application, but we expect they will. They do use the protocol. Then there's the class of people who everybody who got kicked off of Tumblr, who were basically queer and sex positive youth who were doing things that Verizon didn't want to see.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Right.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"There's a whole world of people who are not OnlyFans paid pornography, but are also not things that fit corporate America's ideas of morality.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"So yes to furries, no to Nazis.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Exactly. And then people who are using Mastodon, but want to build a different class of social applications, people who are using Signal and they want privacy, we support scalable private groups. So your messages could be public, they could be directly individual to individual, encrypted or in sort of a scalable private group of encrypted messages. And so people who want a signal style encryption, but not for chat, for social media.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Right.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"And then the last group we're looking at is media companies that want to control their relationship to their audience.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Okay.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Evan Henshaw-Plath:\")), mdx(\"p\", null, \"Newsletter publishers to media outlets with hundreds of employees, they're publishing on Apple, Facebook, Google's platforms and those companies are sometimes giving them a lot of money and then changing the algorithm and then pulling away and then deleting accounts and then charging them 50% of their revenue. And so they want a kind of sovereign control over their relationship to their audience over social media. And right now, they can build their own app or they can run their website with a paywall, or they can put their content out on these platforms where they don't control the relationship.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"So much to think about in here. Really exciting to see it taking off. So many of the same problems and questions that we're facing over at our project, we start from aggregation as our first step, precisely for the reason that you're talking about. One of the things I really have to get my head around is how we aggregate into Planetary, given that you're using a very different approach to URLs and the ability to share posts. But that's a technical conversation we have to have at some point. In the meantime, though, this notion of true decentralization, identity that resides on the phone or on the device and this vision of many different spaces with many different rule sets is so aligned with what we're trying to do. I hope we're going to have a chance to keep talking about this as we both go forward with these projects.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Evan Henshaw-Plath (aka Rabble), founder of Planetary.Social and member of Twitter's founding team, joins the podcast to talk about decentralized social media, how context collapse makes content moderation on platforms like Facebook and Twitter impossible, and building a platform that's safe for people like furries while keeping away people like neo-Nazis. Vist our episode web page for links to Planetary.Social and a transcript of this interview.","frontmatter":{"publicationDate":"2020-11-03T00:00:00.000Z","title":"Evan Henshaw-Plath, Planetary.Social","slug":"/podcast/03-evan-henshaw-plath","url":"https://archive.org/download/03.-evan-henshaw-plath-planetary.-social/03.%20Evan%20Henshaw%20Plath%2C%20Planetary.Social.mp3"}}},{"node":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"type\": \"podcast-episode\",\n  \"status\": \"published\",\n  \"slug\": \"/podcast/02-talia-stroud\",\n  \"featuredImage\": \"../../images/podcast-images/02-talia-stroud.png\",\n  \"guid\": \"publicinfrastructure.org/podcast/02-talia-stroud\",\n  \"title\": \"Talia Stroud, Civic Signals\",\n  \"subtitle\": \"Presented by the Institute for Digital Public Infrastructure at UMass Amherst\",\n  \"publicationDate\": \"2020-10-27T00:00:00.000Z\",\n  \"author\": \"Institute for Digital Public Infrastructure\",\n  \"season\": 1,\n  \"episodeNumber\": 2,\n  \"episodeType\": \"full\",\n  \"excerpt\": \"Talia Stroud from the University of Texas joins us to talk about her project Civic Signals, a project reimagining the Internet as a public space. She walks us through what’s wrong with the type of speech currently rewarded by Facebook and Twitter, and what it might look like to promote civic speech instead. Recorded August, 2020. Visit our episode web page for links to Civic Signals' website and newsletter, and Eli Pariser's TED Talk.\",\n  \"url\": \"https://archive.org/download/02.-talia-stroud-civic-signals/02.%20Talia%20Stroud%2C%20Civic%20Signals.mp3\",\n  \"embed\": \"https://archive.org/embed/02.-talia-stroud-civic-signals\",\n  \"youtubeEmbedURL\": \"https://www.youtube.com/embed/csSZ3zv8otc\",\n  \"duration\": 1442,\n  \"size\": 55000000,\n  \"explicit\": false,\n  \"categories\": [\"Technology\", \"Government\", \"Science\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Talia Stroud from the University of Texas joins us to talk about her project Civic Signals, a project reimagining the Internet as a public space. She walks us through what\\u2019s wrong with the type of speech currently rewarded by Facebook and Twitter, and what it might look like to promote civic speech instead. Recorded August, 2020.\"), mdx(\"p\", null, \"Check out Civic Signals\\u2019 \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://civicsignals.io\"\n  }), \"website\"), \" and subscribe to their \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://civicsignals.substack.com/\"\n  }), \"newsletter\"), \".\"), mdx(\"p\", null, \"Watch \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.ted.com/talks/eli_pariser_what_obligation_do_social_media_platforms_have_to_the_greater_good\"\n  }), \"Eli Pariser\\u2019s TED Talk\"), \".\"), mdx(\"h1\", null, \"Transcript\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I'm thrilled that we have with us today professor \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \". Talia teaches at University of Texas at Austin in the School of Communications and also in the School of Journalism. She is one of the co-founders of the Civic Signals Initiative, which in my opinion is one of the most interesting projects out there looking really explicitly at this idea of how we can tell whether an online social space is having conversations that are useful and helpful for civic health. Talia, thank you so much for being with us today.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"Such a pleasure.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"So what we're doing in this series is talking to a wide variety of people, about two really simple questions. What do you think is wrong with social media as we know it? And what steps are you taking to try to make it better? And given that Civic Signals is really deeply focused on this question of how to make it better, you seem like a great person to start with. So let me put you on the spot and ask you for a diagnosis. What's wrong with social media at this particular point in the middle of 2020?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"Where to start, right? So this is something that my co-founder of Civic Signals, Eli Pariser and I have been thinking a lot about. And we've really been focusing on your second part of your question, which is how to make it better. But let's start with why we need to make it better in the first place. And I think that in the popular world, there are so many things that are going wrong with social media right now. We have the in quotations, \\\"fake news\\\" or the spread of mis- and disinformation. We see people behaving poorly in these spaces and the proliferation of hate speech, et cetera. So I think those are kind of the surface level indicators that something is greatly amiss on social media.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"And if you dig a bit deeper into that, I think that part of the reason that we see this happening is because the way in which social media is structured, they have a profit motivation. And the way to gain profit is to make sure that you have lots of eyeballs and people returning to the social media platforms as frequently as you possibly can. And that they spend lots and lots of time there. And that's how the algorithms for many social media platforms are created.\"), mdx(\"p\", null, \"They figure out how is it that we keep them there as much time as we possibly can throughout the day. And I think that that's actually really a problem because it creates scenarios where the loudest voices are those that are highly partisan, they are saying terrible things. And that gets people coming back again and again. And there's a reward structure there for social media companies because they get advertising dollars as a consequences of that. So I think that this building for profit and doing so in a way that creates algorithms that reward bad behavior is a really problematic aspect of that.\"), mdx(\"p\", null, \"And if I'll add one more thing to this, although I could probably go on the rest of our time on aspects that need to be addressed, when the social media platforms have been called out for the problematic aspects of what they're doing. So, Facebook facing scrutiny or Twitter facing scrutiny for the proliferation of again, quotes \\\"fake news\\\" or the spread of mis- and disinformation, the response there in my mind has really been more of like a whack-a-mole strategy. Like, \\\"Okay, there's the bad thing today and I'm going to hit it that mole. And then, Oh, there's the bad thing tomorrow.\\\"\"), mdx(\"p\", null, \"And yeah, they're developing teams and coming up with some infrastructure to address this, but that's really focused on responding to crisis rather than proactively figuring out, \\\"How do we move this forward?\\\" And as you said earlier, how do we think about this from a, what are some of the civics signals or ways in which we can signal good behavior? Which is actually a really different way of thinking about what social media could and should do.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"So just understanding the diagnosis, you in many ways, sort of a single diagnosis that explaining two symptoms, right? One symptom is this wave of mis- and disinformation that seems to be making it harder and harder to figure out whether we can take anything as fact that we're encountering online.\"), mdx(\"p\", null, \"The second is incivility, abuse, hostility, all these sorts of things that potentially silence people because they simply don't want to deal with that behavior when they're interacting on the platform. And you're linking both of them really to two things, one is to a business model where these companies that are running Facebook, are running Twitter, are running YouTube, these are for-profit companies. At the end of the day, they make money through advertising. And so maximizing eyeballs, maximizing the people looking at the content is to their fiscal advantage. And then we're hypothesizing somewhat, but there's certainly a good arguments why this might be the case, that the algorithms that bring content to the front, that bring it to the top of the Facebook news feed, or that bring it into YouTube's recommender are favoring outrageous, eye-catching, highly emotive content because it's consistent with the business model for these platforms though, not necessarily consistent with what's good for us.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"Two things that I would quickly add is I think that what we see in terms of mis- and disinformation and people questioning what's real or not actually goes beyond online. And it can make people question those things then offline and think, \\\"What do we know in any context?\\\" Which I think is really tricky.\"), mdx(\"p\", null, \"And then on the algorithms favoring outrage, we've done some research where we were looking at just for instance, on the New York Times, what of comments get the most recommendations. And it's those that talk about partisanship and use uncivil language. And if you have an algorithm that rewards things that get lots of interactions, like recommendations, those do percolate to the top. So I think absolutely fair to say that that's something that's happening there.\"), mdx(\"p\", null, \"And then in terms of civic signals, what we're thinking about there is from platform behavior, from anything that happens on a platform, we send all sorts of signals. Right now, the way the architecture of the platforms is set up is that the signals that we're sending that are feeding algorithms are things such as liking a comment on Facebook or replying to something on Twitter. Those send signals. But they're signals that are really based on interactivity and engagement. And those are being used by algorithms to elevate content.\"), mdx(\"p\", null, \"Well, we actually send a much broader array of signals when we interface with these platforms, the words that we write, the words contained in the articles that we share, the impression left by an image. All of these are also signals. And if we think about those as being signals, then there might be some content that's really civically rewarding, and that really helps to create a more public friendly space.\"), mdx(\"p\", null, \"So we've been really thinking about these signals as we've been focused for so long on what's user-friendly, thinking very much at the individual level. And that's what it means to hit like on something. That's your individual behavior rewarding someone else's individual behavior. But what if instead of user-friendly we thought about this as public-friendly. So it's odd that we haven't really gone down this path and it's been so individually focused. But those sorts of signals are so much easier. It's so easy to add up the number of likes and use that to be an algorithm. But figuring out what are the indicators of civically beneficial behavior and do people get these civic rewards when they're taking part in social media? That's really what we wanted to uncover in the Civic Signals Project is thinking through, can we identify signals that platforms are actually having a beneficial influence at a societal or public level?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"One of the things that you seem to be implying is that there's civic content out there, and we just have to work to figure out how to surface it. Is it that easy? Are people really using these tools for civic purposes? And if they are, how do we find it? How do we find the content that would be healthy and helpful for us as a public?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"So I do think that there is civic content out there and we see it. There are fundraisers where people are raising money to deal with a crisis in another country, for example. That's a very civic act. And we see people increasingly doing that, at least on my Facebook feed, for example, for their birthdays. \\\"I'm raising money for such and such, a nonprofit organization.\\\" What a wonderful civic act.\"), mdx(\"p\", null, \"Then you also see people trying to encourage others to sign petitions or to get involved in a variety of ways. Increasingly we see more and more hosts encouraging people to vote in the upcoming election. So I think that there is civic content out there and there's content that helps you humanize another person who you may never have really seen in that light. So I think it exists.\"), mdx(\"p\", null, \"Do I think that that's all that has to happen here is just surfacing what's already existing? I don't think that's the case. I think that there's more to it than that. And I think essentially we have to think about the architecture and we keep using this metaphor of space because we find it so interesting. Eli really honed in on this. But it's the architecture that prioritizes your behavior in certain ways over others. And there has been research for instance, looking at if you design a space and you give all sorts of signals that you should be thoughtful there, like make it look like a library do all of that. People actually act very differently in that space than if you just say, \\\"Hey, leave a message,\\\" or something more casual. And so I think the architecture of these spaces also has to be considered, or is the architecture promoting people's actions in a civic way or not?\"), mdx(\"p\", null, \"And as part of that, I think that that's a call to action essentially to platforms is thinking through not only algorithmically, how you might surface some of this content, but how could you create products and experiences within these platforms, given the opportunity to be citizens in these spaces when we still need these public spaces, particularly now in the middle of coronavirus where there's no space to have public conversations other than in digital life. So I think it's a \\\"yes, and\\\" sort of a situation of surfacing this content that does exist. And making it possible for people who want to have those experiences to find the architecture that supports them.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I like the spatial metaphor a great deal. And I was actually on with a team of designers from Facebook who were thinking about some of these civic challenges. And the explanation that I gave was a church and a pool hall and a library are all public spaces. But they have really, really different affordances. They have different things that you can technically do in them. Most churches don't serve beer, most libraries lack pool tables. But they also have norms. The speech that is acceptable in a pool hall might be different than the speech that's acceptable in church, or that's acceptable in a library.\"), mdx(\"p\", null, \"One of the things that is so incredibly challenging about a space like Facebook is that it is trying to build one room, one single type of room for every sort of frankly, public and private interaction. And it's incredibly hard to think about whether one room could ever meet those needs.\"), mdx(\"p\", null, \"Let's get concrete on that for a second. What's the most surprising civic signal that someone has brought up? The most sort of unexpected or interesting one that's sort of come up in this conversation with a hundred or more experts?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"The one that has been the most vexing, I would say, and it's not perhaps surprising, but really thinking through is actually tricky. And so I would consider this to be surprising is how tricky it is, is there's a theory that dates back several decades called Agenda-Setting, which is the basic idea that if the media cover a particular issue, then that issue is seen as important by the public. And so there was this sense in talking to these variety of experts that that's kind of a responsibility in some ways in social media is to surface these important issues for the public to recognize.\"), mdx(\"p\", null, \"But as soon as you get underneath that a little bit, it's actually much more complicated than that because you can have different subgroups that might have very, very different issue priorities. And how do you then think through what issues to prioritize if one subgroup has quite a different idea of an important issue compared to another?\"), mdx(\"p\", null, \"and where we've settled that in chatting with again, many different people who had perspectives on this is that one important civic signal or one important contribution that social media can make is by surfacing the interests of a variety of different major subgroups. So that if you have one particular subgroup and I'm using subgroups a bit loosely here, but thinking about this in terms of demographic or major political parties, is if an issue of the importance of one of those, not only surfacing it for those people, but surfacing it for those that might actually not be part of that subgroup.\"), mdx(\"p\", null, \"And that I think was, it was surprising to me how a theory that's one that I've taught in my classes for a decade and a half now that I thought was almost a done deal in some ways, turned out to be one of the most conceptually challenging ones to think through because there are so many diverse interests. And I don't think that social media typically consider a responsibility to different divisions within society, which goes back to what you were saying earlier of creating one space that caters to everyone. Well, everyone doesn't always have the same shared interests. So that was one that I found surprising in its complexity.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"I had a funny example of that recently. I've been driving my neighbor up to doctors appointments in Southern Vermont. And I live in Western Mass and weirdly enough, the politics even going in that sort of 30 mile drive can change quite a bit. And here we are surrounded by Black Lives Matter signs. And I drove 30 miles up the road to the nearest big city. And it turns out that there are signs in people's yards that say Black Rifles Matter, which is certainly a very different sentiment. And it's one that it's a useful reminder that it is shared by some of my neighbors.\"), mdx(\"p\", null, \"And it's certainly true that social media, for me, has surfaced an enormous amount of Black Lives Matter content. It has been less good at surfacing the Black Rifles Matter in part because I'm sure on some level, the algorithms know that that is not a political point of view that I support. But it was this nice reminder that we have the ability to inscribe our opinions into physical space, but we can often end up in these really badly circumscribed social spaces, instead of remember that that view out there.\"), mdx(\"p\", null, \"You also mentioned that you got some feedback about the platforms doing a good job with these signals and affordances. What's a case where someone felt like the platforms were doing a good job?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"So in our focus groups, we ask people to tell us about experiences that they had had on social media. And some of the kind of surprising things from doing that, or people's incredible stories that they had about what they gained from being on social media. So it's the story of the grandmother that gets a chance to actually know her grandchild. It's the isolated individual who suddenly reconnects with their high school classmates. There was one story about a woman who didn't have the money I believe to buy a prom dress or something like that. And then everyone rally behind her to make sure she could get it. It's just these beautiful stories of people using social media to these incredible ends that have repercussions for individuals and for us socially. And I think that we tend to forget that a little bit.\"), mdx(\"p\", null, \"So in our survey, we actually asked people to tell us whether they thought that social media made things better for them, worse for them, or didn't really have any effect. Most people think that these in general made their lives much, much better. And even though there are certainly worries and concerns, for the majority of people, these are a net good in their lives overall.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"It is really interesting to think back into the distant, distant past of March, 2020, where we were sort of in the full flush of a tech lash, this sort of movement where there was a real reconsideration, \\\"Are these platforms good for us? Do we like what they're doing to us individually? Do we like what they're doing to us as society?\\\" And in a funny way, the tech lash to a certain extent has been put on hold because at the moment, these are the only public spaces we have. So, we continue to have a tech executives going in front of Congress, but I don't really hear a lot of people talking about boycotting online space for the simple reason that right now, online space is space. And particularly as winter comes to some parts of the country, it's going to become more and more sort of important \", \"[inaudible 00:18:14]\", \".\"), mdx(\"p\", null, \"Let me throw out the question you \", \"[inaudible 00:18:18]\", \" involved with this project, all the experts you've talked to, all the survey work that you're doing, you're putting together a set of recommendations that could be incredibly helpful for a new social media platform. It could be a real roadmap for someone like YouTube or Facebook. How are you going to get these very, very powerful companies to take this advice? What is your feeling about how this work is going to be received and how it might be picked up?\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"So there are different philosophies about how to go about doing this sort of work. And the tone that we've taken is we've actually chatted with folks within the social media platforms as we've gone throughout this process. So we've kept them in the loop. Like, \\\"These are some of the things that we're finding.\\\" And so I think we've been collaborators in a sense, quite external to what they're doing. And it's not something that we needed to call them about every week, but we have made an effort to make sure that they're fully aware of what we're doing so that they can adopt these sorts of strategies as they were thinking moving forward. So that's part of the strategy is making them into the process as we're going throughout it.\"), mdx(\"p\", null, \"And then after that, our full intention is that we'll have briefings inside many of the major platforms to let them know like, \\\"Hey, here's what we found at this point. Here are the sorts of things that we're recommending.\\\" And then I do think that some of the information about how the platforms are performing, sharing that publicly, I think also has an effect in terms of how the platforms will respond to this.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"Yeah, it feels like in a certain way, for this to succeed, there needs to be a bit of a movement behind it. There needs to be a bit of an insistence that the platforms take our collective civic life seriously. And for me, it's one of the places where I see Institute for Digital Public Infrastructure and Civic Signals most allied, which is that we're sharing this common vision that these places, whether we like them or not, are going to be critically important for civics, even if the pandemic ends tomorrow. These are simply the spaces in which we are most likely to have these critically important conversations. And if they don't have the norms or affordances that help us have those conversations, they're going to remain an impoverished space. And over time, they're going to impoverish our democracy more broadly.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"Yeah, I couldn't agree more. And I think that this movement part is a key part of Civic Signals. So there's a newsletter and we're working on developing a community around all of these. We've been really active in terms of seeking out advice along the way, and bringing people with us slash having people bring us with them because we certainly aren't the first people to ever think about these ideas. There really is in my sense, a community forming around this. And I think that we hope that Civic Signals can start to be a place where people come together and kids start to have these conversations, both within platforms and creating new social media outlets and with others like you and the work that you're doing. That we can all come together to say, \\\"Look, now we're all part of this movement that we think this is a really, really important thing for democracy.\\\" To have this conversation and I think through the influence of social media outlets and to think through what the positive vision is that they should be working toward as opposed to whack-a-mole for the negatives.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, \"So Talia, with that shared vision and the notion of a movement in mind, what are things that people can do to get involved with Civic Signals, to learn more about it? Give a takeaway, or sort of a next step that a viewer of this might be able to take.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \":\"), mdx(\"p\", null, \"So in terms of learning more about it, Eli has a TED Talk that is a fantastic place to kind of hear the thinking about space and how this relates to it. And so that would be a great place to learn more. We also have a website where people can sign up for our newsletter. And it's a fantastic newsletter if you haven't seen it. And so that's a great way to get involved. And then we're also will within this next month, be sharing a number of new ways to get involved as well as. So urge you to sign up for that newsletter so you can be first to hear about all of those things. and then we'll be sharing the research also through that newsletter and in the website. And we'll also be doing some public writing about it. So much more to come. Encourage as many peoples as are interested to get involved.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman\"), \":\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Talis Stroud\"), \", Civic Signals, and University of Texas at Austin. Just a pleasure to catch up with you and hear what's going on. I hope more people will check out this project. I think it's one of the most important pieces of research being done right now to sort of understand what signals we would have to monitor to have a really positive vision for what's going on in the future with social media. Thank you so much for being with us.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Talia Stroud from the University of Texas joins us to talk about her project Civic Signals, a project reimagining the Internet as a public space. She walks us through what’s wrong with the type of speech currently rewarded by Facebook and Twitter, and what it might look like to promote civic speech instead. Recorded August, 2020. Visit our episode web page for links to Civic Signals' website and newsletter, and Eli Pariser's TED Talk.","frontmatter":{"publicationDate":"2020-10-27T00:00:00.000Z","title":"Talia Stroud, Civic Signals","slug":"/podcast/02-talia-stroud","url":"https://archive.org/download/02.-talia-stroud-civic-signals/02.%20Talia%20Stroud%2C%20Civic%20Signals.mp3"}}},{"node":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"type\": \"podcast-episode\",\n  \"status\": \"published\",\n  \"slug\": \"/podcast/01-welcome-to-reimagining-the-internet\",\n  \"featuredImage\": \"../../images/pod-social-card.png\",\n  \"guid\": \"publicinfrastructure.org/podcast/01-welcome-to-reimagining-the-internet\",\n  \"title\": \"Welcome to Reimagining the Internet\",\n  \"subtitle\": \"Presented by the Institute for Digital Public Infrastructure at UMass Amherst\",\n  \"publicationDate\": \"2020-10-20T00:00:00.000Z\",\n  \"author\": \"Institute for Digital Public Infrastructure\",\n  \"season\": 1,\n  \"episodeNumber\": 1,\n  \"episodeType\": \"full\",\n  \"excerpt\": \"Our host Ethan Zuckerman introduces iDPI's new podcast, talking about the need to create online spaces in the public interest instead of a corporate profit motive. Join us as we interview activists, scholars, journalists, and entrepreneurs reimagining the internet as we know it today.\",\n  \"url\": \"https://archive.org/download/01-welcome-to-reimagining-the-internet_202010/01-welcome-to-reimagining-the-internet.mp3\",\n  \"embed\": \"https://archive.org/embed/01-welcome-to-reimagining-the-internet_202010\",\n  \"youtubeEmbedURL\": \"https://www.youtube.com/embed/LiPRw2nxguQ\",\n  \"duration\": 1018,\n  \"size\": 38800000,\n  \"explicit\": false,\n  \"categories\": [\"Technology\", \"Government\", \"Science\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Our host Ethan Zuckerman introduces iDPI's new podcast by talking about the need for creating online spaces in the public interest, serving civic good instead of a corporate profit motive. Join us as we interview activists, scholars, journalists, and entrepreneurs reimagining the internet as we know it today.\"), mdx(\"h1\", null, \"Transcript\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Ethan Zuckerman:\")), mdx(\"p\", null, \"Thanks for listening to Reimagining the Internet from the Institute for Digital Public Infrastructure at UMass Amherst. We're hosting an ongoing discussion with researchers, activists, academics, techies, and journalists about what's wrong with the internet and how we might fix it. I'm your host, Ethan Zuckerman.\"), mdx(\"p\", null, \"Generally speaking, Reimagining the Internet is going to be an interview show. I'll be talking to an amazing array of people who are working on really creative projects that imagine the internet working radically different ways than it does today, hence the title of the show. But I want to make sure that I'm being honest with all of you. I'm not a neutral narrator. A lot of the work that I'm doing right now at the University of Massachusetts at Amherst is focused on a very particular view of how the internet could and should work in the future. So for the first episode of this podcast, I'm going to do the awkward work of interviewing myself and tell you a little bit about the Institute for Digital Public Infrastructure, why we're starting a new center to do this and how those views might inform the conversations we're going to be having here with people who have quite different views, in many cases, with both what's wrong with the internet and what we might do to fix it.\"), mdx(\"p\", null, \"So who am I? My name is Ethan Zuckerman. I'm a professor at UMass Amherst. I teach in public policy, in communication and in information and computer science. But the answer is I'm a refugee from the very early days of the internet. In the mid-1990s, I helped start a company called Tripod.com, which was really one of the very first user-generated content companies on the web. It let people put up home pages for free. At the peak of its popularity, it had something like 18 million users per month, which was a whole lot back in the late 1990s when most people weren't using the internet.\"), mdx(\"p\", null, \"The truth is user-generated content was both very new and very old ever. Since the 1970s, the main thing people who have been using the internet for is to share their own writing, whether it's emails, whether it's mailing lists, whether it was Usenet newsgroups, but making this accessible to a whole new generation of people in the 1990s really sparked the movement that we're seeing today with social media, where everybody is a content creator, and therefore everybody has the possibility of trying to influence the much larger social dialogue we have about what's going on in the world and how we view the world that we share.\"), mdx(\"p\", null, \"So from that perspective of watching the internet and helping build it for the last 25 years, there's enormous amounts to be proud of. The internet has made it possible for people all over the world to raise their voices and share their ideas in ways that simply wouldn't have been possible before. I've had the great fortune to be involved with a project called Global Voices, which works to amplify voices of people in the developing world and share them all over the world. That's a project that's now been going on for more than a dozen years with thousands and thousands of posts from people in over a hundred different countries. But on the flip side, there's lots of reasons to be worried about the internet right now, its effect on us individually and the effects on us as a community, and particularly as a political community.\"), mdx(\"p\", null, \"Nearly everyone listening to this will have heard about mis and disinformation, the possibility that the internet and social media are being used to manipulate us and to manipulate elections. The idea that the internet may be pushing us apart, polarizing us, making us less tolerant and more hateful. You may have also heard ideas that the internet is designed for addiction, designed to keep you clicking, that it may be bad for your self image, your self esteem or your mental health. I think all of those concerns are worth taking very seriously. Although, I'd point out that as a scholar in this space, many of those contentions have less support in research than they do in anecdote. But what I'm really interested in is seeing whether we can look at some of the assumptions behind the internet that we work with today and think about whether there's other ways of building a path out of our current problems and towards a better future.\"), mdx(\"p\", null, \"So let's think, first of all, about the logic of the internet. When you use the tool like Facebook, you expect certain things from it. The first one you expect is that it's going to be free to use. Because it's free to use, you expect it to be supported in a particular way, targeted advertising. Advertisers are going to hope to steal a fraction of your attention. They're going to pull you away from what you're actually doing, which is trying to keep up with your friends or maybe stalk your ex or any number of other things people do on Facebook. Those advertisers are going to have a better chance of reaching you, perhaps, because they have data from the platform about what you do, what you like, and maybe intimate details about who you are. The author, Shoshana Zuboff, refers to this model as surveillance capitalism. We collect information about you and your preferences. We use it to target ads to you to sell, which in exchange make services free.\"), mdx(\"p\", null, \"Now, this model has been really great for building and growing companies like Google and Facebook and Twitter and YouTube. It's been pretty great in the sense that it's given a lot of people a chance to connect to old friends, to publish things that they might not otherwise have been able to publish. But it has some real possible downsides. One observation that's been made is that the platforms have a really strong incentive to keep you watching, and therefore the content that they serve you may not just be an unbiased view of what your friends are saying about the world. There's a good chance that Facebook might feed you information that is sensational or highly emotional or one way or another intended to capture your emotions and keep you watching and viewing.\"), mdx(\"p\", null, \"The theory behind this is that if you're seeing more emotional, high emotional valence content, there's a good chance that it might try to sway you politically. Or maybe it might be the sort of content that tries to misinform you about the risks of something like COVID-19. There's a lot of research going on right now trying to figure out how true this is, how much are we actually being manipulated by our feeds. But because the logic of surveillance capitalism works in a particular way, there's ample reason to be concerned. But here's the interesting trick, surveillance capitalism isn't the only possible model for the internet. We know that to be true because there's some really exciting sites out there that work on a different logic.\"), mdx(\"p\", null, \"Consider Wikipedia. Like Facebook, Wikipedia is made by average users. People are allowed to go on and write what they like. Except on Wikipedia, they can't write exactly what they like. They actually have to write within a very specific model. They're writing encyclopedia entries and they can be overwritten and corrected by other users until an article reaches what Wikipedia calls neutral point of view. While it sounds crazy, like having a bunch of monkeys struggling with a typewriter until they write an encyclopedia, it actually has worked remarkably well. Wikipedia is one of the top 10 sites on the internet in virtually every country where it's used and it doesn't accept advertising. It's also not supported by subscription. Instead, it's supported by donation, mostly small donations from its users. It's driven not so much by profit, but by a mission, the mission of making knowledge free and accessible to everyone around the world.\"), mdx(\"p\", null, \"Now, Wikipedia is unusual. It's really one of the very few sites that's been able to work this way, but it offers this intriguing idea that there could be different logics that inform the internet. So I want to suggest a different logic that I've spent a while thinking about, which is the logic of public broadcasting. Most major democracies have a public broadcaster. This is different from having government media where you're hearing propaganda from the government. In countries like Germany and in Britain, the public broadcaster is usually the most respected source of broadcast news. It is supported by taxpayer dollars, but it's governed by an independent board of governors. Because it's under such careful scrutiny, it tends to be extremely careful about not taking it over a political stance in one direction or another.\"), mdx(\"p\", null, \"It too has a mission. Its goal is to provide reliable information that people need as citizens in a democracy and to showcase voices that might not otherwise be heard, particularly from minority populations or parts of the country that might not otherwise be heard from. So what happens if we take a logic like this, a medium that works based on taxpayer support, that has explicit civic goals behind it and apply it to the space of social media? Well, you might get something a little bit like what we're trying to build with Institute for Digital Public Infrastructure. We're talking about public spaces online, spaces where people get together and talk about the future, whether it's politics, whether about their local communities. These are civic spaces, sort of broader than political.\"), mdx(\"p\", null, \"You might not be talking about who's going to win the 2020 US election, but you might be talking about how to revitalize the downtown of your hometown. Right now, most of these conversations take place on platforms that are owned by Facebook, Twitter, Google that work under this logic of surveillance capitalism. They are digital public spaces on top of private infrastructures. We're investigating this idea that maybe we can build these digital public spaces on top of public infrastructures. These would be new spaces. They'd be supported by taxpayer dollars, at least at first. Instead of having the logic of surveillance capitalism and maximizing profit, these are spaces that could work on a civic logic. So you might imagine there could be a social network designed specifically for the people in your town to talk about local issues and it might not be open to anyone outside of your town. These networks don't have to be huge. In fact, maybe they benefit from being small.\"), mdx(\"p\", null, \"You might also imagine a network that you could voluntarily join and have civil arguments with people who have a different political point of view from you. These spaces probably can't be free-for-alls. You'd probably design them to be very heavily moderated. But you might actually have them moderated by the community that uses them. This is a model that we see on websites like Reddit, where people are involved with actually governing the spaces that they work within. Why don't these spaces exist right now? Well, one answer is that they're not very profitable. You don't necessarily make a ton of money hosting a forum where people come together and debate whether we should have a dog park. But that doesn't mean that it's not necessary. In fact, there's lots of things that we ask our societies to pay for as public goods, because we need them not necessarily because they turn an enormous profit.\"), mdx(\"p\", null, \"The other reason that these spaces don't exist is that existing social media networks work pretty hard to make sure that they have a monopoly of eyeballs. Facebook is pretty notorious when other social networks are getting traction for buying them up and incorporating them sometimes as they did with Instagram, or just making sure that they don't grow much further. By stepping outside of the venture capital world and the world in which your investors will always sell a network to a big company like Google or Facebook, and instead accepting this idea that we might invest as a society in building these sorts of spaces, we take ourselves out of that equation.\"), mdx(\"p\", null, \"But we've still got other big problems. Lots and lots of people have tried to reinvent social media. The problem with doing so is that you can start a great social network and there's some exciting new ones out there, but they have a very, very hard time getting up to a large enough size where they have network effects. So if you end up joining Diaspora or Mastodon, you may find that you don't spend as much time on it as you would like to because your friends aren't on it as well. So the work that we're doing at Institute for Digital Public Infrastructure has a lot to do with interoperability. We want to make sure that people can use these new sorts of social networks that we're creating, but that they're still able to use the networks that they already have friends and a presence on like Twitter and Facebook.\"), mdx(\"p\", null, \"In fact, we're going after an idea called adversarial interoperability. We want to be interoperable with these networks, whether they like it or not and that has all sorts of interesting technical and legal implications to it that I'm sure we'll be discussing as we get further within this podcast. Social media isn't the only goal behind the Institute for Digital Public Infrastructure. We're interested in building all sorts of digital tools that move away from a pure advertising surveillance and profit logic and into a logic that's more focused on civics and on healthy online communities. So you'll hear me talk more about this over the course of these interviews. Some of my ideas are sure to creep in.\"), mdx(\"p\", null, \"If you feel like learning more about this, we have a bunch of papers up at publicinfrastructure.org that flesh out the digital public infrastructure idea. But I want to assure you that if you're listening to this and thinking, \\\"This guy's crazy, this will never work,\\\" that doesn't mean you should stop listening to this podcast because the truth is we're going to invite a lot of different people with many different visions for what the internet can and should be to come in and have conversations. Some of the people we're hoping to bring in include some people who are really early pioneers on the internet, who've built some of the things that have made the web that we love and sometimes love to hate as well as some new entrepreneurs, some incredible scholars, some hackers who are really deep down in the trenches of building these new systems.\"), mdx(\"p\", null, \"Our goal is really to give you an overview of a world that if you don't know about it might look really static, but actually is going through an amazing amount of activity and creativity right now. So I hope you'll come back and join us on this podcast, Reimagining the Internet. We're going to be releasing interviews on a semi-regular basis, one every two weeks or so, as we lead up to the launch of this new center at the University of Massachusetts at Amherst. Please feel free to find out more about us at publicinfrastructure.org. I hope you'll tune in and keep listening to the podcast as we go forward.\"), mdx(\"p\", null, \"Reimagining the Internet is hosted by me, Ethan Zuckerman, and produced by Mike Sugarman, who also composed our theme song. Visit publicinfrastructure.org for more information about the launch of our research center at the University of Massachusetts at Amherst in spring 2021. Please subscribe wherever you're listening to this podcast.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Our host Ethan Zuckerman introduces iDPI's new podcast, talking about the need to create online spaces in the public interest instead of a corporate profit motive. Join us as we interview activists, scholars, journalists, and entrepreneurs reimagining the internet as we know it today.","frontmatter":{"publicationDate":"2020-10-20T00:00:00.000Z","title":"Welcome to Reimagining the Internet","slug":"/podcast/01-welcome-to-reimagining-the-internet","url":"https://archive.org/download/01-welcome-to-reimagining-the-internet_202010/01-welcome-to-reimagining-the-internet.mp3"}}}]},"image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABiUlEQVQoz41TS0sCURSeIJUWlZVNkZmUIxGFKeKDqNQeqEGaUZQbiWoR5KJFRMvoJ2VqYmnp+OqFQdTP+br3jkMqai0O55w7c7/7fefBxUc4yHbL1/wwMQ2H2ACHG7XkY4M1L+dDv3fke9S4ekAZLKFV4CUSxJNrDlmnERnbJB4sOhILUm7VIz2jaQBqD0heThnVeA77Gej7SRhvx7v4ujoneQCvByF8XkZR2fcx9vHRrvaA7EXyA5WUnuWRc5tY/rgwjcqel50lxpUQvTZk7QYmn37vKFkGLAaW8H19AdHvQDUaQfU0wvzH2SGxI6SEflbnPyXLTJM6FWGjQHJCJcU6JRJj3Ujqe1hc38R/Sc46BMaSNqZAWOZXLSjvrKG8vYJicJlJpw38F0M6EvdmLXKeeQJkRmnLhcKGE6LPTsAl3zwunSWT2qSEPgJoYuxoQyhD2hzRa2fj04pda8l1oBnbFEohDzE38utWFDcXGcM7Qy8br1Z1bGTIN22MRtoQ6uXtYcZzbZvyA2LPqfgYA7UhAAAAAElFTkSuQmCC","aspectRatio":1.8691588785046729,"src":"/static/51862950008b4d984ccdf07e7e5bfe75/ee604/pod-social-card.png","srcSet":"/static/51862950008b4d984ccdf07e7e5bfe75/69585/pod-social-card.png 200w,\n/static/51862950008b4d984ccdf07e7e5bfe75/497c6/pod-social-card.png 400w,\n/static/51862950008b4d984ccdf07e7e5bfe75/ee604/pod-social-card.png 800w,\n/static/51862950008b4d984ccdf07e7e5bfe75/f3583/pod-social-card.png 1200w,\n/static/51862950008b4d984ccdf07e7e5bfe75/5707d/pod-social-card.png 1600w,\n/static/51862950008b4d984ccdf07e7e5bfe75/c6120/pod-social-card.png 2800w","sizes":"(max-width: 800px) 100vw, 800px"}}}},"pageContext":{}},"staticQueryHashes":["2544187668","3649515864"]}